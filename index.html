<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>YOLO Eye Capture</title>
  <style>
    :root{--bg:#0f172a;--card:#111827;--muted:#94a3b8;--accent:#22c55e;--danger:#ef4444}
    *{box-sizing:border-box}
    body{margin:0;font-family:system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Arial;background:linear-gradient(180deg,#0b1220,#0f172a)}
    header{padding:18px 16px;color:#e5e7eb;display:flex;justify-content:center;border-bottom:1px solid #1f2937;background:#0b1220aa;backdrop-filter:blur(6px);position:sticky;top:0}
    main{max-width:980px;margin:20px auto;padding:16px}
    .card{background:rgba(17,24,39,.9);border:1px solid #1f2937;border-radius:16px;overflow:hidden;color:#e5e7eb;box-shadow:0 10px 30px rgba(0,0,0,.4)}
    .section{padding:16px;border-top:1px dashed #1f2937}
    .section:first-child{border-top:none}
    .grid{display:grid;gap:16px}
    @media(min-width:900px){.grid{grid-template-columns:1.2fr .8fr}}
    .row{display:flex;gap:10px;flex-wrap:wrap;align-items:center}
    input[type="text"]{width:260px;padding:10px;border-radius:10px;border:1px solid #334155;background:#0b1220;color:#e5e7eb}
    input[type="checkbox"]{transform:scale(1.2)}
    button{padding:12px 16px;border-radius:12px;border:1px solid #1f2937;background:#0b1220;color:#e5e7eb;cursor:pointer}
    button.primary{background:linear-gradient(180deg,#16a34a,#16a34a 60%,#15803d);border-color:#14532d}
    button.secondary{background:#0b1220}
    button:disabled{opacity:.5;cursor:not-allowed}
    .video-wrap{position:relative;border-radius:16px;overflow:hidden;border:1px solid #1f2937}
    video,canvas{display:block;width:100%;height:auto}
    canvas.overlay{position:absolute;inset:0;pointer-events:none}
    .muted{color:#94a3b8}
    .ok{color:#22c55e}.err{color:#ef4444}
    .kbd{font-family:ui-monospace,monospace;background:#111827;border:1px solid #1f2937;border-bottom-width:3px;padding:2px 6px;border-radius:6px;color:#cbd5e1}
    .thumb{width:100%;border-radius:12px;border:1px solid #1f2937}
    .mono{font-family:ui-monospace,monospace}
  </style>
  <!-- ONNX Runtime Web -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
</head>
<body>
<header><strong>YOLO Eye Capture</strong></header>
<main>
  <div class="card">
    <div class="section grid">
      <div>
        <h2>Consent & Identification</h2>
        <p class="muted">Please accept image use and enter your name to continue.</p>
        <div class="row" style="margin-top:8px">
          <input id="name" type="text" placeholder="Participant name" />
          <label class="row" style="gap:8px"><input id="consent" type="checkbox"> I consent to the use of my image.</label>
        </div>
        <p id="consentStatus" class="muted" style="margin-top:6px">Status: <span id="consentIcon">❌</span> Missing consent/name</p>
      </div>
      <div>
        <h3>Instructions</h3>
        <ol class="muted" style="line-height:1.7">
          <li>Position yourself in front of the camera.</li>
          <li>Focus your eye on the camera.</li>
          <li>Keep a distance of about 10–15 cm from the camera.</li>
          <li>Open your eye wide.</li>
          <li>Make sure the image is clear and sharp.</li>
          <li>Press the button below to capture the photo.</li>
        </ol>
      </div>
    </div>

    <div class="section">
      <div class="row" style="justify-content:space-between">
        <div class="row">
          <button id="start" class="primary">Enable camera</button>
          <button id="flip" class="secondary" disabled>Switch camera</button>
        </div>
        <div class="row muted">
          <span id="modelStatus">Model: not loaded</span>
          <span>&nbsp;•&nbsp;</span>
          <span id="fps">— fps</span>
        </div>
      </div>
      <div class="video-wrap" style="margin-top:12px">
        <video id="video" playsinline muted></video>
        <canvas id="overlay" class="overlay"></canvas>
      </div>
      <div class="row" style="margin-top:12px;justify-content:space-between">
        <div class="row"><span class="muted">Camera:</span> <span id="camLabel" class="kbd">—</span></div>
        <div class="row"><button id="capture" class="primary" disabled>Capture eye</button></div>
      </div>
    </div>

    <div class="section grid">
      <div>
        <h3>Result</h3>
        <img id="thumb" class="thumb" alt="Eye crop">
      </div>
      <div>
        <h3>Upload</h3>
        <p class="muted">The cropped eye will be uploaded to Google Drive.</p>
        <div id="uploadLog" class="mono muted">Ready.</div>
      </div>
    </div>

    <div class="section muted">
      <small>Privacy: detection runs entirely in your browser. Only the final crop is uploaded when you click “Capture eye”.</small>
    </div>
  </div>
</main>

<script>
/* =================== CONFIG =================== */
// Model (change if needed)
const MODEL_URL = "https://huggingface.co/pedro123gtz/yolo-eye-model/resolve/main/best.onnx";
const MODEL_INPUT_SIZE = 320;          // detección rápida (no afecta la calidad de la foto final)
const MODEL_CONF_THRESHOLD = 0.35;
const MODEL_IOU_THRESHOLD  = 0.45;
const MODEL_CLASSES = ["eye"];

const DRIVE_WEBAPP_URL = "https://script.google.com/macros/s/AKfycbxXx18hiOBFQR_eEsxVxp5ye6K84Nt1M0wVGJ1ObTagKt0tkGj5vFPEbsKggOybhbEZ/exec";
const DRIVE_SECRET = "456";               // si usas token, pon el mismo en EXPECTED del Apps Script
const DRIVE_FOLDER = "Eyes_data";
const DRIVE_FOLDER_ID = "1xIspp2gSZ5tZKYQJ7VsVTdh2rTg2ohD4"; // tu carpe

/* =================== STATE/DOM =================== */
const $ = s => document.querySelector(s);
const nameInput=$("#name"), consentInput=$("#consent"), consentIcon=$("#consentIcon"), consentStatus=$("#consentStatus");
const startBtn=$("#start"), flipBtn=$("#flip"), captureBtn=$("#capture");
const modelStatus=$("#modelStatus"), fpsLabel=$("#fps"), video=$("#video"), overlay=$("#overlay"), ctx=overlay.getContext("2d");
const camLabel=$("#camLabel"), thumb=$("#thumb"), uploadLog=$("#uploadLog");

let streaming=false, currentStream=null, useFrontCamera=true;
let lastDetections=[], track=null;
let tick=0, RUN_EVERY=3; // run detector once every 3 frames

/* =================== UI helpers =================== */
function updateConsentState(){
  const ok = !!nameInput.value.trim() && consentInput.checked;
  consentIcon.textContent = ok ? "✅" : "❌";
  consentStatus.className = ok ? "ok" : "err";
  startBtn.disabled = !ok;
}
nameInput.addEventListener('input', updateConsentState);
consentInput.addEventListener('change', updateConsentState);
updateConsentState();

/* =================== Eye API (face-api.js style) =================== */
window.eyeapi = (function(){
  const api = {};
  api.nets = {
    eyeDetector: {
      session: null,
      async loadFromUrl(url, providers=['webgpu','wasm']){
        for(const ep of providers){
          try{
            this.session = await ort.InferenceSession.create(url, { executionProviders:[ep] });
            return { provider: ep };
          }catch(e){}
        }
        throw new Error('Could not load model.');
      }
    }
  };
  class EyeDetectorOptions{
    constructor({ inputSize=MODEL_INPUT_SIZE, confThreshold=MODEL_CONF_THRESHOLD, iouThreshold=MODEL_IOU_THRESHOLD }={}){
      this.inputSize=inputSize; this.confThreshold=confThreshold; this.iouThreshold=iouThreshold;
    }
  }
  api.EyeDetectorOptions = EyeDetectorOptions;

  function postprocess(out, meta, confTh, iouTh){
    let data = out.data; let numBoxes, numAttrs;
    if(out.dims.length===3){ const [n,a,b]=out.dims; numBoxes=b; numAttrs=a;
      const tr=new Float32Array(numBoxes*numAttrs);
      for(let i=0;i<a;i++) for(let j=0;j<b;j++) tr[j*numAttrs+i]=data[i*b+j];
      data=tr;
    } else if(out.dims.length===2){ numBoxes=out.dims[0]; numAttrs=out.dims[1]; } else { return []; }
    const boxes=[], scores=[], classes=[];
    const sig=x=>1/(1+Math.exp(-x));
    for(let i=0;i<numBoxes;i++){
      const off=i*numAttrs; const x=data[off], y=data[off+1], w=data[off+2], h=data[off+3];
      const obj=sig(data[off+4]); let cls=1, cid=0;
      if(numAttrs>5){ let best=0, id=0; for(let c=5;c<numAttrs;c++){ const sc=sig(data[off+c]); if(sc>best){best=sc; id=c-5;} } cls=best; cid=id; }
      const conf=obj*cls; if(conf<confTh) continue;
      boxes.push([x-w/2,y-h/2,x+w/2,y+h/2]); scores.push(conf); classes.push(cid);
    }
    const keep=(function(b,s,iouT,maxDet=50){
      const ord=s.map((v,i)=>[v,i]).sort((A,B)=>B[0]-A[0]).map(x=>x[1]); const out=[];
      function iou(a,b){ const x1=Math.max(a[0],b[0]), y1=Math.max(a[1],b[1]), x2=Math.min(a[2],b[2]), y2=Math.min(a[3],b[3]);
        const w=Math.max(0,x2-x1), h=Math.max(0,y2-y1), inter=w*h, A=(a[2]-a[0])*(a[3]-a[1]), B=(b[2]-b[0])*(b[3]-b[1]); return inter/(A+B-inter+1e-6); }
      for(const i of ord){ let ok=true; for(const j of out){ if(iou(b[i],b[j])>iouT){ ok=false; break; } } if(ok){ out.push(i); if(out.length>=maxDet) break; } }
      return out;
    })(boxes, scores, iouTh);
    const res=[];
    for(const i of keep){
      const [x1,y1,x2,y2]=boxes[i]; const {ratio,dx,dy,iw,ih}=meta;
      const sx1=(x1-dx)/ratio, sy1=(y1-dy)/ratio, sx2=(x2-dx)/ratio, sy2=(y2-dy)/ratio;
      const X1=Math.max(0,Math.min(iw,sx1)), Y1=Math.max(0,Math.min(ih,sy1)), X2=Math.max(0,Math.min(iw,sx2)), Y2=Math.max(0,Math.min(ih,sy2));
      res.push({ box:[X1,Y1,X2,Y2], score:scores[i], label:(MODEL_CLASSES[classes[i]]||`c${classes[i]}`) });
    }
    return res;
  }

  api.detectAllEyes = async function(input, opts=new EyeDetectorOptions()){
    const sess = api.nets.eyeDetector.session;
    if(!sess) throw new Error('Model not loaded');
    const lb = letterbox(input, opts.inputSize);
    const px = lb.canvas.getContext('2d').getImageData(0,0,lb.canvas.width,lb.canvas.height).data;
    const size = opts.inputSize*opts.inputSize; const arr=new Float32Array(size*3);
    for(let i=0,p=0;i<size;i++,p+=4){ arr[i]=px[p]/255; arr[i+size]=px[p+1]/255; arr[i+2*size]=px[p+2]/255; }
    const t0 = performance.now();
    const out = await sess.run({ [sess.inputNames[0]]: new ort.Tensor('float32', arr, [1,3,opts.inputSize,opts.inputSize]) });
    const dt = performance.now()-t0; fpsLabel.textContent = `${(1000/dt).toFixed(1)} fps`;
    return postprocess(out[sess.outputNames[0]], lb, opts.confThreshold, opts.iouThreshold);
  };

  return api;
})();

/* =================== Utils & Tracking =================== */
function letterbox(img,newSize){
  const iw=img.videoWidth||img.width, ih=img.videoHeight||img.height; const r=Math.min(newSize/iw,newSize/ih);
  const nw=Math.round(iw*r), nh=Math.round(ih*r), dx=Math.floor((newSize-nw)/2), dy=Math.floor((newSize-nh)/2);
  const c=document.createElement('canvas'); c.width=newSize; c.height=newSize; const t=c.getContext('2d');
  t.fillStyle='#000'; t.fillRect(0,0,newSize,newSize); t.drawImage(img,0,0,iw,ih,dx,dy,nw,nh);
  return {canvas:c, ratio:r, dx, dy, iw, ih};
}
const STABILITY={ confMin:0.55, minAreaRatio:0.005, ema:0.35, iouKeep:0.50, maxCoast:6, requireStableFrames:8 };
const area=b=>Math.max(0,b[2]-b[0])*Math.max(0,b[3]-b[1]);
const iou=(a,b)=>{const x1=Math.max(a[0],b[0]),y1=Math.max(a[1],b[1]),x2=Math.min(a[2],b[2]),y2=Math.min(a[3],b[3]);const w=Math.max(0,x2-x1),h=Math.max(0,y2-y1),inter=w*h,A=(a[2]-a[0])*(a[3]-a[1]),B=(b[2]-b[0])*(b[3]-b[1]);return inter/(A+B-inter+1e-6);}
const ema=(p,c,a)=>[p[0]*(1-a)+c[0]*a,p[1]*(1-a)+c[1]*a,p[2]*(1-a)+c[2]*a,p[3]*(1-a)+c[3]*a];
function chooseBest(dets){
  const W=overlay.width,H=overlay.height,minA=STABILITY.minAreaRatio*W*H;
  const norm=dets.map(d=>({ ...d, xyxy:d.xyxy||d.box }));
  const f=norm.filter(d=>d.score>=STABILITY.confMin && area(d.xyxy)>=minA);
  if(!f.length) return null; f.sort((a,b)=>b.score-a.score); return f[0];
}
function drawTrack(t){
  ctx.clearRect(0,0,overlay.width,overlay.height); if(!t) return;
  const [x1,y1,x2,y2]=t.box, w=x2-x1, h=y2-y1;
  ctx.lineWidth=3; ctx.strokeStyle='#22c55e'; ctx.fillStyle='rgba(34,197,94,.12)';
  ctx.beginPath(); ctx.rect(x1,y1,w,h); ctx.stroke(); ctx.fill();
  const tag=`eye ${(t.score*100).toFixed(0)}% · ${t.stable}f`;
  ctx.font='16px ui-monospace,monospace'; const tw=ctx.measureText(tag).width+10;
  ctx.fillStyle='#0b1220'; ctx.fillRect(x1,Math.max(0,y1-22),tw,22);
  ctx.fillStyle='#93c5fd'; ctx.fillText(tag,x1+5,Math.max(16,y1-6));
}
function updateCaptureState(){ captureBtn.disabled = !(track && track.stable>=STABILITY.requireStableFrames); }

/* =================== Camera =================== */
async function startCamera(){
  if(currentStream){ currentStream.getTracks().forEach(t=>t.stop()); }
  const facingMode = useFrontCamera ? 'user' : 'environment';
  try{
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode, width:{ideal:1280}, height:{ideal:720} },
      audio: false
    });
    currentStream=stream; video.srcObject=stream; await video.play();
    overlay.width=video.videoWidth; overlay.height=video.videoHeight;
    camLabel.textContent=facingMode; flipBtn.disabled=false; streaming=true;
  }catch(err){ alert('Could not access camera: '+err.message); }
}
flipBtn.addEventListener('click', async ()=>{ useFrontCamera=!useFrontCamera; await startCamera(); });

startBtn.addEventListener('click', async ()=>{
  await startCamera();
  await loadModel();
  detectLoop();
});

/* =================== Model =================== */
async function loadModel(){
  modelStatus.textContent='Model: loading…';
  try{
    const { provider } = await eyeapi.nets.eyeDetector.loadFromUrl(MODEL_URL, ['webgpu','wasm']);
    // warm-up
    const tmp=document.createElement('canvas'); tmp.width=MODEL_INPUT_SIZE; tmp.height=MODEL_INPUT_SIZE;
    await eyeapi.detectAllEyes(tmp, new eyeapi.EyeDetectorOptions({ inputSize:MODEL_INPUT_SIZE, confThreshold:0.99 }));
    modelStatus.textContent=`Model: ready (${provider})`;
  }catch(e){ console.error(e); modelStatus.textContent='Model: load error'; }
}

/* =================== Detection loop =================== */
async function detectLoop(){
  const opts=new eyeapi.EyeDetectorOptions({ inputSize:MODEL_INPUT_SIZE, confThreshold:MODEL_CONF_THRESHOLD, iouThreshold:MODEL_IOU_THRESHOLD });
  while(streaming){
    try{
      tick++; if(tick % RUN_EVERY !== 0){ drawTrack(track); updateCaptureState(); await new Promise(r=>setTimeout(r,10)); continue; }
      const dets = await eyeapi.detectAllEyes(video, opts);
      const best = chooseBest(dets);
      if(!track && best){ track={ box:[...best.xyxy], score:best.score, stable:1, coast:0 }; }
      else if(track){
        if(best){ const m=iou(track.box, best.xyxy); if(m>=STABILITY.iouKeep){ track.box=ema(track.box, best.xyxy, STABILITY.ema); track.score=best.score; track.stable++; track.coast=0; } else { track.coast++; } }
        else { track.coast++; }
        if(track.coast>STABILITY.maxCoast) track=null;
      }
      drawTrack(track); updateCaptureState();
    }catch(e){ console.error(e); await new Promise(r=>setTimeout(r,100)); }
    await new Promise(r=>setTimeout(r,10));
  }
}

/* =================== Capture & upload =================== */
function cropToBlob(det){
  const [x1,y1,x2,y2]=det.xyxy.map(v=>Math.round(v));
  const w=Math.max(1,x2-x1), h=Math.max(1,y2-y1);
  const c=document.createElement('canvas'); c.width=w; c.height=h;
  c.getContext('2d').drawImage(video,x1,y1,w,h,0,0,w,h);
  return new Promise(res=> c.toBlob(b=>res(b),'image/jpeg',0.95));
}

// Upload: try multipart (reads JSON). If the browser blocks it, fallback to no-cors.
async function uploadToDrive(blob){
  uploadLog.textContent = 'Uploading…';
  const ts = new Date().toISOString().replace(/[:.]/g,'-');
  const fname = `${(nameInput.value.trim() || 'anon')}_${ts}.jpg`;

  // Attempt 1 — multipart/form-data (simple CORS)
  try{
    const form = new FormData();
    form.append('file', blob, fname);
    form.append('name', nameInput.value.trim() || 'anon');
    form.append('folderId', DRIVE_FOLDER_ID);
    form.append('secret', DRIVE_SECRET);

    const resp = await fetch(DRIVE_WEBAPP_URL, {
      method:'POST', body: form,
      cache:'no-store', redirect:'follow', credentials:'omit', referrerPolicy:'no-referrer'
    });

    const text = await resp.text();
    let json; try { json = JSON.parse(text); } catch { throw new Error(`Non-JSON response: ${text.slice(0,180)}`); }
    if(!resp.ok || json.error){ throw new Error(`HTTP ${resp.status} · ${json.error || text}`); }

    uploadLog.textContent = `OK: ${json.fileUrl || 'saved'}`;
    return;
  }catch(err1){
    console.warn('Multipart failed; retrying no-cors:', err1);
  }

  // Attempt 2 — fire-and-forget (no-cors). It uploads but we can’t read the JSON.
  try{
    const form2 = new FormData();
    form2.append('file', blob, fname);
    form2.append('name', nameInput.value.trim() || 'anon');
    form2.append('folderId', DRIVE_FOLDER_ID);
    form2.append('secret', DRIVE_SECRET);

    await fetch(DRIVE_WEBAPP_URL, { method:'POST', body: form2, mode:'no-cors' });
    uploadLog.textContent = 'Sent (no-cors). Please check the "Eyes_data" folder in Drive.';
  }catch(err2){
    uploadLog.textContent = 'Upload error: ' + err2.message;
    console.error('Upload error:', err2);
  }
}

captureBtn.addEventListener('click', async ()=>{
  if(!track || track.stable<STABILITY.requireStableFrames){
    alert('Keep the eye steady for a moment until the box stabilizes.'); return;
  }
  const blob = await cropToBlob({xyxy: track.box});
  thumb.src = URL.createObjectURL(blob);
  await uploadToDrive(blob);
});

// Optional: quick ping to verify connectivity
(async function pingWebApp(){
  try{
    const r = await fetch(DRIVE_WEBAPP_URL, { method:'GET', cache:'no-store' });
    const t = await r.text();
    console.log('WebApp ping:', r.status, t);
  }catch(e){ console.warn('Ping failed:', e); }
})();
</script>
</body>
</html>